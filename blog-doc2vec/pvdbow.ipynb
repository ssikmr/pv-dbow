{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shashikumar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# nltk.download('reuters') ##\n",
    "nltk.download('punkt')\n",
    "\n",
    "PERCENTAGE_DOCS = 100 # random subsample of Reuters training docs\n",
    "VOCAB_SIZE = 10000\n",
    "REMOVE_TOP_K_TERMS = 1 #100\n",
    "MIN_TERM_FREQ = 1 #5 CHANGED\n",
    "\n",
    "TEXT_WINDOW_SIZE = 5\n",
    "BATCH_SIZE = 1 * TEXT_WINDOW_SIZE #10\n",
    "EMBEDDING_SIZE = 30 #128\n",
    "SHUFFLE_EVERY_X_EPOCH = 5\n",
    "PV_TEST_SET_PERCENTAGE = 20\n",
    "NUM_STEPS = 10001\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_SAMPLED = 2 #64\n",
    "REPORT_EVERY_X_STEPS = 200\n",
    "\n",
    "END_TO_END_EVERY_X_STEPS = 3000\n",
    "E2E_TEST_SET_PERCENTAGE = 30\n",
    "TSNE_NUM_DOCS = 400\n",
    "\n",
    "# Token integer ids for special tokens\n",
    "UNK = 0\n",
    "NULL = 1\n",
    "\n",
    "num_attrib = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns an eternal generator, periodically shuffling the order\n",
    "\n",
    "l_ is a list of integers; an internal copy of it is maintained.\n",
    "\"\"\"\n",
    "def repeater_shuffler(l_):\n",
    "    l = np.array(l_, dtype=np.int32)\n",
    "    epoch = 0\n",
    "    while epoch >= 0:\n",
    "        if epoch % SHUFFLE_EVERY_X_EPOCH == 0:\n",
    "            np.random.shuffle(l)\n",
    "        for i in l:\n",
    "            yield i\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_doc(fileid):\n",
    "    return fileid.startswith('training/') \\\n",
    "            and np.random.random() * 100 < PERCENTAGE_DOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept(word):\n",
    "    # Accept if not only Unicode non-word characters are present\n",
    "    return re.sub(r'\\W', '', word) != ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(word):\n",
    "    return word.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 5 columns):\n",
      "index          120 non-null int64\n",
      "CallDate       120 non-null object\n",
      "Vertabim       120 non-null object\n",
      "Subcategory    120 non-null object\n",
      "Category       120 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "### Filename CSV\n",
    "\n",
    "filename = 'sample_data.csv'\n",
    "df = pd.read_csv(filename, encoding=\"latin-1\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'Vertabim'\n",
    "cat_col = 'Category'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_dict(df, cat_col):\n",
    "    dict_cat = enumdict(df[cat_col].unique())\n",
    "    reverse_dict_cat = dict(zip(dict_cat.values(), dict_cat.keys()))\n",
    "    return dict_cat, reverse_dict_cat\n",
    "\n",
    "def enumdict(listed):\n",
    "    myDict = {}\n",
    "    for i,x in enumerate(listed):\n",
    "        myDict[x] = i\n",
    "    return myDict\n",
    "\n",
    "dict_cat, reverse_dict_cat = get_cat_dict(df, cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    fileid2words = {ind:\n",
    "            [normalize(word) for word in word_tokenize(\n",
    "                    df.iloc[ind][text_col]) if accept(word)] \\\n",
    "            for ind in df.index }\n",
    "    \n",
    "    \n",
    "#     print(fileid2words)\n",
    "#     fileid2words = {fileid:\n",
    "#             [normalize(word) for word in word_tokenize(\n",
    "#                     reuters.raw(fileid)) if accept(word)] \\\n",
    "#             for fileid in reuters.fileids() if accept_doc(fileid)}\n",
    "    count = [['__UNK__', 0], ['__NULL__', 0]]\n",
    "    count.extend([(word, count) for word, count in collections.Counter(\n",
    "            [word for words in fileid2words.values() \\\n",
    "            for word in words]).most_common(\n",
    "                    VOCAB_SIZE - 2 + REMOVE_TOP_K_TERMS)[\n",
    "                            REMOVE_TOP_K_TERMS:\n",
    "                    ] if count >= MIN_TERM_FREQ])\n",
    "    assert not set(['__UNK__', '__NULL__']) & set(next(zip(\n",
    "            *count[2:])))\n",
    "    dictionary = {}\n",
    "    for i, (word, _) in enumerate(count):\n",
    "        dictionary[word] = i\n",
    "    reverse_dictionary = dict(zip(dictionary.values(),\n",
    "                                  dictionary.keys()))\n",
    "    data = []\n",
    "    doclens = []\n",
    "    fileids = []\n",
    "    for docid, (fileid, words) in enumerate(fileid2words.items()):\n",
    "        for word in words:\n",
    "            if word in dictionary:\n",
    "                wordid = dictionary[word]\n",
    "            else:\n",
    "                wordid = UNK\n",
    "                count[UNK][1] += 1\n",
    "                \n",
    "            # category Id\n",
    "            data.append((docid, wordid, dict_cat[df.iloc[docid][cat_col]]))\n",
    "        # Pad with NULL values if necessary\n",
    "        doclen = len(words)\n",
    "        doclens.append(doclen)\n",
    "        fileids.append(fileid)\n",
    "        if doclen < TEXT_WINDOW_SIZE:\n",
    "            n_nulls = TEXT_WINDOW_SIZE - doclen\n",
    "            data.extend([(docid, NULL, dict_cat[df.iloc[docid][cat_col]])] * n_nulls)\n",
    "            count[NULL][1] += n_nulls\n",
    "    return data, count, doclens, fileids, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment\n",
    "dn = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "                columns=['a', 'b', 'c'])\n",
    "\n",
    "# print(dn)\n",
    "# for ind in dn.index:\n",
    "#     print(ind)\n",
    "#     print(dn.iloc[ind]['b'])\n",
    "\n",
    "# dic = {'1' : 2, '2' : 3}\n",
    "# dic['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, count, doclens, fileids, dictionary, reverse_dictionary = \\\n",
    "        build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 120\n",
      "Number of tokens: 1284\n",
      "Number of unique tokens: 56\n",
      "Most common words (+UNK and NULL): [['__UNK__', 155], ['__NULL__', 0], ('your', 79), ('on', 79), ('the', 79)]\n",
      "Least common words: [('separate', 1), ('plants', 1), ('volunteers', 1), ('been', 1), ('use', 1)]\n",
      "Sample data: [(0, 0, 0), (0, 2, 0), (0, 10, 0), (0, 11, 0), (0, 9, 0)]\n",
      "Effective vocab size: 56\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents:', len(set(next(zip(*data)))))\n",
    "print('Number of tokens:', len(data))\n",
    "print('Number of unique tokens:', len(count))\n",
    "assert len(data) == sum([i for _, i in count])\n",
    "print('Most common words (+UNK and NULL):', count[:5])\n",
    "print('Least common words:', count[-5:])\n",
    "print('Sample data:', data[:5])\n",
    "vocab_size = min(VOCAB_SIZE, len(count))\n",
    "print('Effective vocab size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean      10.700000\n",
       "std        1.921134\n",
       "min        8.000000\n",
       "25%        8.000000\n",
       "50%       12.000000\n",
       "75%       12.000000\n",
       "max       15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(doclens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 8, 12, 12, 15, 12, 12, 8, 12, 12, 8, 12, 12, 8, 9, 12, 8, 12, 12, 8]\n"
     ]
    }
   ],
   "source": [
    "print(doclens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_window_center_positions():\n",
    "    # If TEXT_WINDOW_SIZE is even, then define text_window_center\n",
    "    # as left-of-middle-pair\n",
    "    doc_start_indexes = [0]\n",
    "    last_docid = data[0][0]\n",
    "    for i, (d, _, _) in enumerate(data):\n",
    "        if d != last_docid:\n",
    "            doc_start_indexes.append(i)\n",
    "            last_docid = d\n",
    "    twcp = []\n",
    "    for i in range(len(doc_start_indexes) - 1):\n",
    "        twcp.extend(list(range(\n",
    "                doc_start_indexes[i] + (TEXT_WINDOW_SIZE - 1) // 2,\n",
    "                doc_start_indexes[i + 1] - TEXT_WINDOW_SIZE // 2\n",
    "                )))\n",
    "    return doc_start_indexes, twcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_start_indexes, twcp = get_text_window_center_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test():\n",
    "    split_point = len(twcp) * (100 - PV_TEST_SET_PERCENTAGE) // 100\n",
    "    twcp_train = twcp[:split_point]\n",
    "\n",
    "    # Test set data must come from known documents\n",
    "    docids_train = set([data[i][0] for i in twcp_train])\n",
    "    twcp_test = []\n",
    "    # CHANGED LOOKS opposite\n",
    "    for i in twcp[split_point:]:\n",
    "        if data[i][0] in docids_train:\n",
    "            twcp_test.append(i)\n",
    "        else:\n",
    "            twcp_train.append(i)\n",
    "    if len(twcp_test) < (BATCH_SIZE // TEXT_WINDOW_SIZE):\n",
    "        raise ValueError(\n",
    "            'Too little test data, try increasing PV_TEST_SET_PERCENTAGE')\n",
    "    return twcp_train, twcp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(twcp)\n",
    "twcp_train, twcp_test = get_train_test()\n",
    "twcp_train_gen = repeater_shuffler(twcp_train)\n",
    "# print(twcp)\n",
    "del twcp # save some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective test set percentage: 160 out of 800, 20.0%\n"
     ]
    }
   ],
   "source": [
    "print('Effective test set percentage: {} out of {}, {:.1f}%'.format(\n",
    "        len(twcp_test), len(twcp_test) + len(twcp_train),\n",
    "        100 * len(twcp_test) / (len(twcp_test) + len(twcp_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "del twcp_train # save some memory, we use twcp_train_gen from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_single_twcp(twcp, i, batch, labels, category):\n",
    "    tw_start = twcp - (TEXT_WINDOW_SIZE - 1) // 2\n",
    "    tw_end = twcp + TEXT_WINDOW_SIZE // 2 + 1\n",
    "    docids, wordids, cotids = zip(*data[tw_start:tw_end])\n",
    "    batch_slice = slice(i * TEXT_WINDOW_SIZE,\n",
    "                        (i+1) * TEXT_WINDOW_SIZE)\n",
    "    batch[batch_slice] = docids\n",
    "    labels[batch_slice, 0] = wordids\n",
    "    category[batch_slice] = cotids\n",
    "    \n",
    "def generate_batch(twcp_gen):\n",
    "    batch = np.ndarray(shape=(BATCH_SIZE,), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(BATCH_SIZE, 1), dtype=np.int32)\n",
    "    category = np.ndarray(shape=(BATCH_SIZE,), dtype=np.int32)\n",
    "    for i in range(BATCH_SIZE // TEXT_WINDOW_SIZE):\n",
    "        generate_batch_single_twcp(next(twcp_gen), i, batch, labels, category)\n",
    "    return batch, labels, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "CAT_NUM = len(dict_cat)\n",
    "TEST_SIZE = 100\n",
    "NUM_POSSIBLE_CAT= CAT_NUM + TEST_SIZE + 1\n",
    "\n",
    "dataset = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "category = tf.placeholder(tf.int32, shape = [BATCH_SIZE]) #new\n",
    "labels = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 1])\n",
    "\n",
    "# Weights\n",
    "doc_embeddings = tf.Variable(\n",
    "        tf.random_uniform([len(doclens), EMBEDDING_SIZE],\n",
    "                          -1.0, 1.0))\n",
    "cat_embeddings =  tf.Variable(\n",
    "        tf.random_uniform([NUM_POSSIBLE_CAT, EMBEDDING_SIZE],\n",
    "                          -1.0, 1.0))\n",
    "\n",
    "\n",
    "softmax_weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "                [vocab_size, (num_attrib+1) * EMBEDDING_SIZE],\n",
    "                stddev=1.0 / np.sqrt(EMBEDDING_SIZE)))\n",
    "softmax_biases = tf.Variable(tf.zeros([vocab_size]))\n",
    "\n",
    "# Model\n",
    "# Look up embeddings for inputs\n",
    "doc_embed = tf.nn.embedding_lookup(doc_embeddings, dataset)\n",
    "cat_embed = tf.nn.embedding_lookup(cat_embeddings, category)\n",
    "\n",
    "embed = tf.concat([doc_embed, cat_embed], axis = 1)\n",
    "\n",
    "# Compute the softmax loss, using a sample of the negative\n",
    "# labels each time\n",
    "loss = tf.reduce_mean(\n",
    "        tf.nn.sampled_softmax_loss(\n",
    "                softmax_weights, softmax_biases, \n",
    "                labels,embed, NUM_SAMPLED, vocab_size))\n",
    "\n",
    "# Optimizer # CHANGED\n",
    "# trainable_param = []\n",
    "optimizer_train = tf.train.AdagradOptimizer(LEARNING_RATE).minimize(\n",
    "        loss)\n",
    "\n",
    "optimizer_test = tf.train.AdagradOptimizer(LEARNING_RATE).minimize(\n",
    "        loss, var_list = [doc_embeddings, cat_embeddings])\n",
    "\n",
    "\n",
    "\n",
    "# Test loss\n",
    "test_loss = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits = tf.matmul(embed, tf.transpose(\n",
    "                          softmax_weights)) + softmax_biases,\n",
    "                labels = labels[:, 0]))\n",
    "\n",
    "# Normalized embeddings (to use cosine similarity later on)\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(doc_embeddings), 1,\n",
    "                              keep_dims=True))\n",
    "normalized_embeddings = doc_embeddings / norm\n",
    "\n",
    "# Normalized embeddings (to use cosine similarity later on)\n",
    "cat_norm = tf.sqrt(tf.reduce_sum(tf.square(cat_embeddings), 1,\n",
    "                              keep_dims=True))\n",
    "cat_normalized_embeddings = cat_embeddings / cat_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loss():\n",
    "    # We do this in batches, too, to keep memory usage low.\n",
    "    # Since our graph works with a fixed batch size, we\n",
    "    # are lazy and just compute test loss on all batches that\n",
    "    # fit in the test set.\n",
    "    twcp_test_gen = (i for i in twcp_test)\n",
    "    n_batches = (len(twcp_test) * TEXT_WINDOW_SIZE) // BATCH_SIZE\n",
    "    test_l = 0.0\n",
    "    for _ in range(n_batches):\n",
    "        batch_data, batch_labels, batch_category = generate_batch(twcp_test_gen)\n",
    "        test_l += session.run([test_loss], feed_dict={\n",
    "                dataset: batch_data, labels: batch_labels, category : batch_category\n",
    "            })[0]\n",
    "    return test_l / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_steps):\n",
    "    avg_training_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batch_data, batch_labels, batch_category = generate_batch(twcp_train_gen)\n",
    "        _, l = session.run(\n",
    "                [optimizer_train, loss],\n",
    "                feed_dict={dataset: batch_data, labels: batch_labels, category : batch_category})\n",
    "        avg_training_loss += l\n",
    "        if step > 0 and step % REPORT_EVERY_X_STEPS == 0:\n",
    "            avg_training_loss = \\\n",
    "                    avg_training_loss / REPORT_EVERY_X_STEPS\n",
    "            # The average loss is an estimate of the loss over the\n",
    "            # last REPORT_EVERY_X_STEPS batches\n",
    "            print('Average loss at step {:d}: {:.1f}'.format(\n",
    "                    step, avg_training_loss))\n",
    "            avg_training_loss = 0\n",
    "            test_l = get_test_loss()\n",
    "            print('Test loss at step {:d}: {:.1f}'.format(\n",
    "                    step, test_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_labels():\n",
    "#     most_common_class = collections.Counter(\n",
    "#             [c for cs in [df.iloc[fileid][cat_col] for fileid in fileids] \\\n",
    "#             for c in cs]).most_common(1)[0][0]\n",
    "#     print('Most common class in sampled documents:',\n",
    "#           most_common_class)\n",
    "#     return (\n",
    "#             np.array(\n",
    "#                     [1 if most_common_class in reuters.categories(\n",
    "#                             fileid) else 0 for fileid in fileids], \n",
    "#                      dtype=np.int32),\n",
    "#             ('other', most_common_class)\n",
    "#             )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e2e_labels, target_names = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_d_embeddings(embeddings):\n",
    "    num_points = min(TSNE_NUM_DOCS, len(fileids))\n",
    "    tsne = TSNE(perplexity=3, n_components=2, init='pca', \n",
    "                n_iter=5000)\n",
    "    return tsne.fit_transform(embeddings[0:num_points, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(embeddings):\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "#     class_1 = e2e_labels[:embeddings.shape[0]].astype('bool')\n",
    "#     plt.plot(embeddings[class_1, 0], embeddings[class_1, 1], \n",
    "#              'o', color='purple')\n",
    "#     plt.plot(embeddings[~class_1, 0], embeddings[~class_1, 1],\n",
    "#              'o', color='lightgrey')\n",
    "    plt.plot(embeddings[ 0], embeddings[ 1],\n",
    "             'o', color='purple')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_e2e_train_test():\n",
    "    indices = np.array(range(len(fileids)), dtype=np.int32)\n",
    "    np.random.shuffle(indices)\n",
    "    split_point = len(indices) * (100 - E2E_TEST_SET_PERCENTAGE) \\\n",
    "            // 100\n",
    "    e2e_train =np.array([True if i in indices[:split_point] \\\n",
    "                         else False for i in range(len(fileids))])\n",
    "    return e2e_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_train = get_e2e_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classification_experiment(embeddings):\n",
    "#     X = embeddings[e2e_train, :]\n",
    "#     y = e2e_labels[e2e_train]\n",
    "#     clf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "#     clf.fit(X, y)\n",
    "#     predictions = clf.predict(\n",
    "#             embeddings[~e2e_train, :])\n",
    "#     print(classification_report(\n",
    "#             e2e_labels[~e2e_train],\n",
    "#             predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end(num_steps):\n",
    "    train(num_steps)\n",
    "    current_embeddings, cat_embeddings = session.run([normalized_embeddings, cat_normalized_embeddings])\n",
    "    print(current_embeddings.shape)\n",
    "    print(cat_embeddings.shape)\n",
    "    plot(get_two_d_embeddings(current_embeddings))\n",
    "#     classification_experiment(current_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for i in range(NUM_STEPS // END_TO_END_EVERY_X_STEPS):\n",
    "        end_to_end(END_TO_END_EVERY_X_STEPS)\n",
    "    end_to_end(NUM_STEPS % END_TO_END_EVERY_X_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 200: 0.7\n",
      "Test loss at step 200: 3.0\n",
      "Average loss at step 400: 0.7\n",
      "Test loss at step 400: 2.7\n",
      "Average loss at step 600: 0.6\n",
      "Test loss at step 600: 2.6\n",
      "Average loss at step 800: 0.6\n",
      "Test loss at step 800: 2.7\n",
      "Average loss at step 1000: 0.5\n",
      "Test loss at step 1000: 2.6\n",
      "Average loss at step 1200: 0.5\n",
      "Test loss at step 1200: 2.6\n",
      "Average loss at step 1400: 0.5\n",
      "Test loss at step 1400: 2.6\n",
      "Average loss at step 1600: 0.5\n",
      "Test loss at step 1600: 2.6\n",
      "Average loss at step 1800: 0.5\n",
      "Test loss at step 1800: 2.5\n",
      "Average loss at step 2000: 0.5\n",
      "Test loss at step 2000: 2.5\n",
      "Average loss at step 2200: 0.6\n",
      "Test loss at step 2200: 2.5\n",
      "Average loss at step 2400: 0.5\n",
      "Test loss at step 2400: 2.5\n",
      "Average loss at step 2600: 0.5\n",
      "Test loss at step 2600: 2.5\n",
      "Average loss at step 2800: 0.5\n",
      "Test loss at step 2800: 2.5\n",
      "(120, 30)\n",
      "(103, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 200: 0.4\n",
      "Test loss at step 200: 2.5\n",
      "Average loss at step 400: 0.5\n",
      "Test loss at step 400: 2.4\n",
      "Average loss at step 600: 0.5\n",
      "Test loss at step 600: 2.5\n",
      "Average loss at step 800: 0.5\n",
      "Test loss at step 800: 2.4\n",
      "Average loss at step 1000: 0.5\n",
      "Test loss at step 1000: 2.5\n",
      "Average loss at step 1200: 0.5\n",
      "Test loss at step 1200: 2.4\n",
      "Average loss at step 1400: 0.5\n",
      "Test loss at step 1400: 2.4\n",
      "Average loss at step 1600: 0.4\n",
      "Test loss at step 1600: 2.4\n",
      "Average loss at step 1800: 0.4\n",
      "Test loss at step 1800: 2.4\n",
      "Average loss at step 2000: 0.5\n",
      "Test loss at step 2000: 2.4\n",
      "Average loss at step 2200: 0.5\n",
      "Test loss at step 2200: 2.4\n",
      "Average loss at step 2400: 0.4\n",
      "Test loss at step 2400: 2.4\n",
      "Average loss at step 2600: 0.4\n",
      "Test loss at step 2600: 2.4\n",
      "Average loss at step 2800: 0.5\n",
      "Test loss at step 2800: 2.4\n",
      "(120, 30)\n",
      "(103, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 200: 0.4\n",
      "Test loss at step 200: 2.4\n",
      "Average loss at step 400: 0.4\n",
      "Test loss at step 400: 2.4\n",
      "Average loss at step 600: 0.4\n",
      "Test loss at step 600: 2.4\n",
      "Average loss at step 800: 0.4\n",
      "Test loss at step 800: 2.4\n",
      "Average loss at step 1000: 0.4\n",
      "Test loss at step 1000: 2.4\n",
      "Average loss at step 1200: 0.4\n",
      "Test loss at step 1200: 2.4\n",
      "Average loss at step 1400: 0.5\n",
      "Test loss at step 1400: 2.4\n",
      "Average loss at step 1600: 0.4\n",
      "Test loss at step 1600: 2.4\n",
      "Average loss at step 1800: 0.4\n",
      "Test loss at step 1800: 2.4\n",
      "Average loss at step 2000: 0.4\n",
      "Test loss at step 2000: 2.4\n",
      "Average loss at step 2200: 0.4\n",
      "Test loss at step 2200: 2.4\n",
      "Average loss at step 2400: 0.5\n",
      "Test loss at step 2400: 2.4\n",
      "Average loss at step 2600: 0.4\n",
      "Test loss at step 2600: 2.4\n",
      "Average loss at step 2800: 0.4\n",
      "Test loss at step 2800: 2.4\n",
      "(120, 30)\n",
      "(103, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 200: 0.4\n",
      "Test loss at step 200: 2.4\n",
      "Average loss at step 400: 0.5\n",
      "Test loss at step 400: 2.4\n",
      "Average loss at step 600: 0.5\n",
      "Test loss at step 600: 2.4\n",
      "Average loss at step 800: 0.4\n",
      "Test loss at step 800: 2.4\n",
      "Average loss at step 1000: 0.5\n",
      "Test loss at step 1000: 2.4\n",
      "(120, 30)\n",
      "(103, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%mprun -f train run() # only works on physical file functions ;-(\n",
    "%lprun -f train run() # uncomment to use (time profiling)\n",
    "#%timeit -n 1 run() # uncomment to use (summary time profiling)\n",
    "#%memit -r 1 run() # uncomment to use (memory consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
